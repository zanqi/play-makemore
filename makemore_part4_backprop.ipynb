{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makemore: becoming a backprop ninja\n",
    "\n",
    "swole doge style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there no change change in the first several cells from last lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3511, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = -1/n * torch.zeros_like(logprobs).scatter_(1, Yb.view(-1,1), 1.0)\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "dprobs = 1 / probs * dlogprobs\n",
    "cmp('probs', dprobs, probs)\n",
    "\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "\n",
    "dcounts2 = torch.ones_like(counts) * dcounts_sum\n",
    "dcounts = dcounts + dcounts2 # product rule of derivative\n",
    "cmp('counts', dcounts, counts)\n",
    "\n",
    "dnorm_logits = counts * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "\n",
    "dlogits = dnorm_logits.clone()\n",
    "# dlogits2 = torch.zeros_like(logits)\n",
    "# dlogits2[range(dlogits2.shape[0]), logits.argmax(1)] = 1\n",
    "dlogits2 = torch.zeros_like(logits).scatter_(1, logits.argmax(1).unsqueeze(-1), 1.0)\n",
    "dlogits2 *= dlogit_maxes\n",
    "dlogits += dlogits2\n",
    "cmp('logits', dlogits, logits)\n",
    "\n",
    "dh = dlogits @ W2.T\n",
    "cmp('h', dh, h)\n",
    "dW2 = h.T @ dlogits\n",
    "cmp('W2', dW2, W2)\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "dhpreact = (1 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "dbnraw = bngain * dhpreact\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "\n",
    "dbnvar = -0.5 * (bnvar + 1e-5)**-1.5 * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "dbndiff2 = 1/(n-1) * torch.ones_like(bndiff2) * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbndiff += 2*bndiff*dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "\n",
    "dbnmeani = -dbndiff.sum(0, keepdim=True)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "\n",
    "dhprebn = dbndiff.clone()\n",
    "dhprebn +=  1/n * torch.ones_like(hprebn) * dbnmeani\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "cmp('embcat', dembcat, embcat)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "cmp('W1', dW1, W1)\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('b1', db1, b1)\n",
    "\n",
    "demb = dembcat.view(emb.shape)\n",
    "cmp('emb', demb, emb)\n",
    "\n",
    "dC = torch.zeros_like(C)\n",
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[i, j]\n",
    "        dC[ix] += demb[i, j]\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1770169e0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dlogits2.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7253e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [-5.5879e-09],\n",
       "        [ 6.2864e-09],\n",
       "        [ 5.1223e-09],\n",
       "        [-2.3283e-10],\n",
       "        [-1.3970e-09],\n",
       "        [ 4.6566e-10],\n",
       "        [ 2.3283e-09],\n",
       "        [-3.2596e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [ 1.3970e-09],\n",
       "        [ 3.2596e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [ 4.6566e-10],\n",
       "        [ 0.0000e+00],\n",
       "        [ 3.9581e-09],\n",
       "        [-9.3132e-10],\n",
       "        [ 4.6566e-10],\n",
       "        [ 3.4925e-09],\n",
       "        [ 3.2596e-09],\n",
       "        [-5.8208e-09],\n",
       "        [ 5.5879e-09],\n",
       "        [ 1.1642e-09],\n",
       "        [-2.3283e-10],\n",
       "        [-4.8894e-09],\n",
       "        [-6.0536e-09],\n",
       "        [-3.2596e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [-9.3132e-10]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes # it should be close to zeros because it is just being subtracted from logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]), torch.Size([32, 27]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape, probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1) # probs.clone(), but if we are using F.cross_entropy, we won't produce probs\n",
    "dlogits[range(n), Yb] -= 1\n",
    "# dlogits[range(n), Yb] /= n\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.351067543029785 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0795, 0.0829, 0.0185, 0.0509, 0.0206, 0.0814, 0.0243, 0.0354, 0.0161,\n",
       "        0.0334, 0.0383, 0.0367, 0.0382, 0.0293, 0.0357, 0.0134, 0.0093, 0.0183,\n",
       "        0.0174, 0.0499, 0.0540, 0.0210, 0.0253, 0.0686, 0.0547, 0.0253, 0.0217],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0795,  0.0829,  0.0185,  0.0509,  0.0206,  0.0814,  0.0243,  0.0354,\n",
       "        -0.9839,  0.0334,  0.0383,  0.0367,  0.0382,  0.0293,  0.0357,  0.0134,\n",
       "         0.0093,  0.0183,  0.0174,  0.0499,  0.0540,  0.0210,  0.0253,  0.0686,\n",
       "         0.0547,  0.0253,  0.0217], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.7940e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x176ded2d0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact_fast.shape, hprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7838\n",
      "  10000/ 200000: 2.1578\n",
      "  20000/ 200000: 2.4185\n",
      "  30000/ 200000: 2.4660\n",
      "  40000/ 200000: 2.0097\n",
      "  50000/ 200000: 2.4323\n",
      "  60000/ 200000: 2.3775\n",
      "  70000/ 200000: 1.9942\n",
      "  80000/ 200000: 2.3335\n",
      "  90000/ 200000: 2.1565\n",
      " 100000/ 200000: 1.9960\n",
      " 110000/ 200000: 2.2912\n",
      " 120000/ 200000: 1.9236\n",
      " 130000/ 200000: 2.4368\n",
      " 140000/ 200000: 2.2994\n",
      " 150000/ 200000: 2.1591\n",
      " 160000/ 200000: 1.9662\n",
      " 170000/ 200000: 1.8608\n",
      " 180000/ 200000: 2.0028\n",
      " 190000/ 200000: 1.8893\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0723588466644287\n",
      "val 2.112560987472534\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I achieved:\n",
    "# train 2.0718822479248047\n",
    "# val 2.1162495613098145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlah.\n",
      "amille.\n",
      "khi.\n",
      "mrix.\n",
      "taty.\n",
      "sacarlie.\n",
      "mahnen.\n",
      "delynn.\n",
      "jareen.\n",
      "ner.\n",
      "kiah.\n",
      "maiivon.\n",
      "leigh.\n",
      "ham.\n",
      "joce.\n",
      "quinthorline.\n",
      "liveni.\n",
      "watell.\n",
      "dearyn.\n",
      "kai.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
